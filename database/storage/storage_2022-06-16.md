# arxiv-daily
 Automated deployment @ 2022-06-16 09:45:25
> Add your topics and keywords in `database/topic.yml` 
> You can also view historical data through the `database/storage` 

## Reasoning

### Math Reasoning
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2022-06-14**|**FETILDA: An Effective Framework For Fin-tuned Embeddings For Long Financial Text Documents**|Bolun "Namir" Xia et.al.|[2206.06952v1](http://arxiv.org/abs/2206.06952v1)|[link](https://github.com/namir0806/fetilda)|
|**2022-06-14**|**The Maximum Linear Arrangement for trees under projectivity and planarity**|Llu√≠s Alemany-Puig et.al.|[2206.06924v1](http://arxiv.org/abs/2206.06924v1)|null|
|**2022-06-13**|**JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem Understanding**|Wayne Xin Zhao et.al.|[2206.06315v1](http://arxiv.org/abs/2206.06315v1)|[link](https://github.com/rucaibox/jiuzhang)|

### Logical Reasoning
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2022-06-13**|**JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem Understanding**|Wayne Xin Zhao et.al.|[2206.06315v1](http://arxiv.org/abs/2206.06315v1)|[link](https://github.com/rucaibox/jiuzhang)|
|**2022-06-13**|**Introducing Proof Tree Automata and Proof Tree Graphs**|Valentin D. Richard et.al.|[2206.06294v1](http://arxiv.org/abs/2206.06294v1)|null|
|**2022-06-13**|**A Sahlqvist-style Correspondence Theorem for Linear-time Temporal Logic**|Rui Li et.al.|[2206.05973v1](http://arxiv.org/abs/2206.05973v1)|null|
|**2022-06-07**|**Plot Writing From Pre-Trained Language Models**|Yiping Jin et.al.|[2206.03021v1](http://arxiv.org/abs/2206.03021v1)|[link](https://github.com/yipingnus/scratchplot-story-generation)|
|**2022-06-02**|**NeuralSympCheck: A Symptom Checking and Disease Diagnostic Neural Model with Logic Regularization**|Aleksandr Nesterov et.al.|[2206.00906v1](http://arxiv.org/abs/2206.00906v1)|[link](https://github.com/sympcheck/neuralsymptomchecker)|
|**2022-05-30**|**Detecting fake news by enhanced text representation with multi-EDU-structure awareness**|Yuhang Wang et.al.|[2205.15139v1](http://arxiv.org/abs/2205.15139v1)|null|
|**2022-05-27**|**Understanding Long Programming Languages with Structure-Aware Sparse Attention**|Tingting Liu et.al.|[2205.13730v1](http://arxiv.org/abs/2205.13730v1)|[link](https://github.com/alibaba/EasyNLP)|
|**2022-05-26**|**Revisiting Generative Commonsense Reasoning: A Pre-Ordering Approach**|Chao Zhao et.al.|[2205.13183v1](http://arxiv.org/abs/2205.13183v1)|null|
|**2022-05-25**|**NaturalProver: Grounded Mathematical Proof Generation with Language Models**|Sean Welleck et.al.|[2205.12910v1](http://arxiv.org/abs/2205.12910v1)|[link](https://github.com/wellecks/naturalproofs)|
|**2022-05-25**|**On the solvability of weakly linear systems of fuzzy relation equations**|Stefan Stanimirovic et.al.|[2205.15292v1](http://arxiv.org/abs/2205.15292v1)|null|
|**2022-05-25**|**Reasoning over Logically Interacted Conditions for Question Answering**|Haitian Sun et.al.|[2205.12898v1](http://arxiv.org/abs/2205.12898v1)|null|
|**2022-05-25**|**PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation**|Ao Liu et.al.|[2205.12697v1](http://arxiv.org/abs/2205.12697v1)|null|
|**2022-05-25**|**RobustLR: Evaluating Robustness to Logical Perturbation in Deductive Reasoning**|Soumya Sanyal et.al.|[2205.12598v1](http://arxiv.org/abs/2205.12598v1)|null|

## Question Answering

### QA
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2022-06-14**|**Task Transfer and Domain Adaptation for Zero-Shot Question Answering**|Xiang Pan et.al.|[2206.06705v1](http://arxiv.org/abs/2206.06705v1)|[link](https://github.com/adityaarunsinghal/Domain-Adaptation)|
|**2022-06-14**|**CHQ-Summ: A Dataset for Consumer Healthcare Question Summarization**|Shweta Yadav et.al.|[2206.06581v2](http://arxiv.org/abs/2206.06581v2)|[link](https://github.com/shwetanlp/yahoo-chq-summ)|
|**2022-06-14**|**LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks**|Tuan Dinh et.al.|[2206.06565v2](http://arxiv.org/abs/2206.06565v2)|[link](https://github.com/uw-madison-lee-lab/languageinterfacedfinetuning)|
|**2022-06-13**|**Memory-Based Model Editing at Scale**|Eric Mitchell et.al.|[2206.06520v1](http://arxiv.org/abs/2206.06520v1)|null|
|**2022-06-13**|**Automatic generation of a large dictionary with concreteness/abstractness ratings based on a small human dictionary**|Vladimir Ivanov et.al.|[2206.06200v1](http://arxiv.org/abs/2206.06200v1)|null|
|**2022-06-12**|**Fine-tuning Pre-trained Language Models with Noise Stability Regularization**|Hang Hua et.al.|[2206.05658v1](http://arxiv.org/abs/2206.05658v1)|null|
|**2022-06-11**|**A Decomposition-Based Approach for Evaluating Inter-Annotator Disagreement in Narrative Analysis**|Effi Levi et.al.|[2206.05446v1](http://arxiv.org/abs/2206.05446v1)|null|
|**2022-06-10**|**Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning**|Aditi Chaudhary et.al.|[2206.05154v1](http://arxiv.org/abs/2206.05154v1)|null|
|**2022-06-10**|**Less Is More: Linear Layers on CLIP Features as Powerful VizWiz Model**|Fabian Deuser et.al.|[2206.05281v1](http://arxiv.org/abs/2206.05281v1)|null|
|**2022-06-10**|**Ask to Know More: Generating Counterfactual Explanations for Fake Claims**|Shih-Chieh Dai et.al.|[2206.04869v2](http://arxiv.org/abs/2206.04869v2)|[link](https://github.com/yilihsu/asktoknowmore)|
|**2022-06-09**|**Defending Compositionality in Emergent Languages**|Michal Auersperger et.al.|[2206.04751v1](http://arxiv.org/abs/2206.04751v1)|null|
|**2022-06-09**|**Jewelry Shop Conversational Chatbot**|Safa Zaid et.al.|[2206.04659v1](http://arxiv.org/abs/2206.04659v1)|null|
|**2022-06-09**|**Privacy Leakage in Text Classification: A Data Extraction Approach**|Adel Elmahdy et.al.|[2206.04591v1](http://arxiv.org/abs/2206.04591v1)|null|
|**2022-06-09**|**Revisiting End-to-End Speech-to-Text Translation From Scratch**|Biao Zhang et.al.|[2206.04571v1](http://arxiv.org/abs/2206.04571v1)|[link](https://github.com/bzhangGo/zero)|
|**2022-06-09**|**Corpus Similarity Measures Remain Robust Across Diverse Languages**|Haipeng Li et.al.|[2206.04332v1](http://arxiv.org/abs/2206.04332v1)|null|
|**2022-06-09**|**Analyzing Folktales of Different Regions Using Topic Modeling and Clustering**|Jacob Werzinsky et.al.|[2206.04221v1](http://arxiv.org/abs/2206.04221v1)|null|
|**2022-06-08**|**Few-shot Question Generation for Personalized Feedback in Intelligent Tutoring Systems**|Devang Kulshreshtha et.al.|[2206.04187v1](http://arxiv.org/abs/2206.04187v1)|null|
|**2022-06-08**|**Resolving the Human Subjects Status of Machine Learning's Crowdworkers**|Divyansh Kaushik et.al.|[2206.04039v1](http://arxiv.org/abs/2206.04039v1)|null|
|**2022-06-07**|**Revealing Single Frame Bias for Video-and-Language Learning**|Jie Lei et.al.|[2206.03428v1](http://arxiv.org/abs/2206.03428v1)|[link](https://github.com/jayleicn/singularity)|
|**2022-06-07**|**cViL: Cross-Lingual Training of Vision-Language Models using Knowledge Distillation**|Kshitij Gupta et.al.|[2206.03354v2](http://arxiv.org/abs/2206.03354v2)|[link](https://github.com/kshitij98/cvil)|
|**2022-06-07**|**Intra-agent speech permits zero-shot task acquisition**|Chen Yan et.al.|[2206.03139v1](http://arxiv.org/abs/2206.03139v1)|null|
|**2022-06-07**|**Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for Answer Retrieval**|Yanmeng Wang et.al.|[2206.02978v1](http://arxiv.org/abs/2206.02978v1)|null|
|**2022-06-06**|**No Parameter Left Behind: How Distillation and Model Size Affect Zero-Shot Retrieval**|Guilherme Moraes Rosa et.al.|[2206.02873v2](http://arxiv.org/abs/2206.02873v2)|[link](https://github.com/guilhermemr04/scaling-zero-shot-retrieval)|
|**2022-06-06**|**Investigating the use of Paraphrase Generation for Question Reformulation in the FRANK QA system**|Nick Ferguson et.al.|[2206.02737v1](http://arxiv.org/abs/2206.02737v1)|null|
|**2022-06-06**|**Learning to Ask Like a Physician**|Eric Lehman et.al.|[2206.02696v1](http://arxiv.org/abs/2206.02696v1)|null|
|**2022-06-06**|**Automatically Drafting Ontologies from Competency Questions with FrODO**|Aldo Gangemi et.al.|[2206.02485v1](http://arxiv.org/abs/2206.02485v1)|[link](https://github.com/anuzzolese/frodo)|
|**2022-06-06**|**Domain-specific Language Pre-training for Dialogue Comprehension on Clinical Inquiry-Answering Conversations**|Zhengyuan Liu et.al.|[2206.02428v1](http://arxiv.org/abs/2206.02428v1)|null|
|**2022-06-06**|**On the Advance of Making Language Models Better Reasoners**|Yifei Li et.al.|[2206.02336v2](http://arxiv.org/abs/2206.02336v2)|null|
